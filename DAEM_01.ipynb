{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "65462fc5",
      "metadata": {
        "id": "65462fc5"
      },
      "source": [
        "![seoultech logo small.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dfd9f2b",
      "metadata": {
        "id": "3dfd9f2b"
      },
      "source": [
        "# Lab Session # 1: NumPy & pandas\n",
        "---\n",
        "\n",
        "by Prof. Josué Obregón <br>\n",
        "Data Analysis for Electronic Manufacturing <br>\n",
        "Department of Data Science - SeoulTech<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4cfeea",
      "metadata": {
        "id": "ab4cfeea"
      },
      "source": [
        "## Learning Objectives\n",
        "- Understand **why** we use NumPy (arrays) and pandas (tabular data).\n",
        "- Use essential **NumPy** concepts: array creation, shapes, indexing/slicing, basic operations.\n",
        "- Use **pandas** for real quick data exploration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e38caef",
      "metadata": {
        "id": "2e38caef"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/2400/0*eNwKHW934I1awMzH.png\" width=\"200\"/>\n",
        "</div>\n",
        "\n",
        "# Session 1 — NumPy Essentials\n",
        "\n",
        "The `numpy` package (module) is used in almost all numerical computation using Python. It is a package that provide high-performance vector, matrix and higher-dimensional data structures for Python. It is implemented in C and Fortran so when calculations are **vectorized** (formulated with vectors and matrices), the performance is very good.\n",
        "\n",
        "To use `numpy` you need to import the module. By convention, the NumPy module imported under the alias np, like so::\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "```\n",
        "\n",
        "After this, we can access functions and classes in the numpy module using the np namespace.\n",
        "\n",
        "Let's import numpy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWpb-LCqmb8v"
      },
      "id": "QWpb-LCqmb8v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy arrays\n",
        "In the numpy package the terminology used for vectors, matrices and higher-dimensional data sets is *array*.\n",
        "\n",
        "But first, what is an array? Let's refresh a bit.\n",
        "\n",
        "In computer science, an array data structure, or simply an array, is a data structure consisting of a collection of elements, each identified by at least one array index or key.\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/mg8O3kd.png)"
      ],
      "metadata": {
        "id": "z0_wKv9amk_V"
      },
      "id": "z0_wKv9amk_V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy provides the **ndarray** (n‑dimensional array) which is a fast, contiguous, homogeneous container for numbers.\n",
        "We cover only the **basics** that directly help when working with pandas:\n",
        "- Arrays vs Python lists\n",
        "- Creating arrays: `np.array`, `np.arange`, `np.linspace`\n",
        "- Inspecting shape & dtype: `.shape`, `.reshape`, `.dtype`\n",
        "- Indexing & slicing\n",
        "- Basic operations: `sum`, `mean`, broadcasting\n"
      ],
      "metadata": {
        "id": "402A5RgomXjc"
      },
      "id": "402A5RgomXjc"
    },
    {
      "cell_type": "markdown",
      "id": "93026a76",
      "metadata": {
        "id": "93026a76"
      },
      "source": [
        "### Arrays vs Lists\n",
        "- **List**: general-purpose Python container (can hold mixed types), slower for numeric operations.\n",
        "- **NumPy array**: fixed-type, efficient numeric container; supports vectorized operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f1df32",
      "metadata": {
        "id": "e5f1df32"
      },
      "outputs": [],
      "source": [
        "# List vs array example\n",
        "py_list = [1, 2, 3, 4, 5]\n",
        "np_array = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "print(\"Python list * 2:\", py_list * 2)        # list repetition\n",
        "print(\"NumPy array * 2:\", np_array * 2)       # elementwise multiplication\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c09f8ca6",
      "metadata": {
        "id": "c09f8ca6"
      },
      "source": [
        "### Creating Arrays\n",
        "Common constructors you'll see used within pandas internals or when preparing data:\n",
        "- `np.array([...])`  \n",
        "- `np.arange(start, stop, step)` _The interval does not include the stop_ value,  \n",
        "- `np.linspace(start, stop, num_points)`  _using linspace, both end points ARE included_\n",
        "- `np.random.rand(d0,d1,...)`\n",
        "- `np.zeros(dimension)`\n",
        "- `np.ones(dimension)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f09be585",
      "metadata": {
        "id": "f09be585"
      },
      "outputs": [],
      "source": [
        "a = np.array([10, 20, 30])\n",
        "b = np.arange(0, 10, 2)       # 0, 2, 4, 6, 8\n",
        "c = np.linspace(0, 1, 5)      # 0.00, 0.25, 0.50, 0.75, 1.00\n",
        "d = np.random.rand(5)\n",
        "e = np.random.rand(5,3)\n",
        "f = np.zeros(5)\n",
        "g = np.ones((3,2))\n",
        "\n",
        "print(\"a:\", a)\n",
        "print(\"b:\", b)\n",
        "print(\"c:\", c)\n",
        "print(\"d:\", d)\n",
        "print(\"e:\", e)\n",
        "print(\"f:\", f)\n",
        "print(\"g:\", g)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment yourself changing the value of the parameters and create different arrays"
      ],
      "metadata": {
        "id": "ebSpC6IRozGC"
      },
      "id": "ebSpC6IRozGC"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tAq0X12o5Mf"
      },
      "id": "1tAq0X12o5Mf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f8c56b19",
      "metadata": {
        "id": "f8c56b19"
      },
      "source": [
        "### Inspecting Arrays\n",
        "Arrays have **shape** and **dtype**. You can **reshape** without copying when compatible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a494a54c",
      "metadata": {
        "id": "a494a54c"
      },
      "outputs": [],
      "source": [
        "m = np.arange(1, 13)         # 1..12\n",
        "print(\"m:\", m)\n",
        "print(\"m.shape:\", m.shape, \"| dtype:\", m.dtype)\n",
        "\n",
        "M = m.reshape(3, 4)\n",
        "print(\"M:\\n\", M)\n",
        "print(\"M.shape:\", M.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment yourself reshaping the arrays you created before and checking the new shape and the dtype"
      ],
      "metadata": {
        "id": "WklvVSt2rwhs"
      },
      "id": "WklvVSt2rwhs"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zORJ7LYUrwht"
      },
      "execution_count": null,
      "outputs": [],
      "id": "zORJ7LYUrwht"
    },
    {
      "cell_type": "markdown",
      "id": "61555360",
      "metadata": {
        "id": "61555360"
      },
      "source": [
        "### Indexing & Slicing\n",
        "\n",
        "We can index elements in an array using square brackets and indices:\n",
        "\n",
        "```python\n",
        "# vec is a vector, and has only one dimension, taking one index\n",
        "vec[0]\n",
        "\n",
        "# mat is a matrix, or a 2 dimensional array, taking two indices\n",
        "mat[1,1]\n",
        "mat[1][1]\n",
        "```\n",
        "\n",
        "Thus is similar to lists, but extended to multiple dimensions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_2YomOMxdQp"
      },
      "source": [
        "If we omit an index of a multidimensional array it returns the whole row (or, in general, a N-1 dimensional array)\n",
        "\n",
        "```python\n",
        "mat[1]  # row 1\n",
        "```"
      ],
      "id": "0_2YomOMxdQp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440mi1vKxdQp"
      },
      "source": [
        "The same thing can be achieved with using `:` instead of an index:\n",
        "\n",
        "```python\n",
        "mat[1,:] # row 1\n",
        "mat[0,:] # row 0\n",
        "mat[:,1] # column 1\n",
        "```"
      ],
      "id": "440mi1vKxdQp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12c74b38",
      "metadata": {
        "id": "12c74b38"
      },
      "outputs": [],
      "source": [
        "M = np.arange(1, 13).reshape(3, 4)\n",
        "print(\"M:\\n\", M)\n",
        "print(\"M[0, 0] ->\", M[0, 0])      # first row, first col\n",
        "print(\"M[:, 1] ->\", M[:, 1])      # all rows, second col\n",
        "print(\"M[2, :] ->\", M[:, 1])      # third row, all cols\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Index slicing is the technical name for the syntax `mat[lower:upper:step]` to extract part of an array:\n",
        "\n",
        "Let's create the following array:\n",
        "\n",
        "```python\n",
        "a = np.array([1,2,3,4,5])\n",
        "```\n",
        "\n",
        "After that, let's try the previous sintax as follows:\n",
        "\n",
        "```python\n",
        "a[1:3]  # array([2, 3])\n",
        "```\n"
      ],
      "metadata": {
        "id": "p4wstBj6tSts"
      },
      "id": "p4wstBj6tSts"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"M[1:, 2:] ->\\n\", M[1:, 2:])  # rows 1..end, cols 2..end"
      ],
      "metadata": {
        "id": "FEcCgzvqtPJz"
      },
      "id": "FEcCgzvqtPJz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can omit any of the three parameters in `M[lower:upper:step]`:\n",
        "\n",
        "```python\n",
        "a[::] # lower, upper, step all take the default values\n",
        "a[::2] # step is 2, lower and upper defaults to the beginning and end of the array\n",
        "a[:3] # first three elements\n",
        "a[3:] # elements from index 3\n",
        "```\n",
        "\n",
        "Let's try out with `M`"
      ],
      "metadata": {
        "id": "n8qLcK5DttuW"
      },
      "id": "n8qLcK5DttuW"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNoN9UXQtr7z"
      },
      "id": "PNoN9UXQtr7z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a multidimensional array (12,12) and experiment yourself accessing other elements of your array with indexing and slicing"
      ],
      "metadata": {
        "id": "vNxCjUVSsmyi"
      },
      "id": "vNxCjUVSsmyi"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azROcopis6VE"
      },
      "id": "azROcopis6VE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9aa6e3e8",
      "metadata": {
        "id": "9aa6e3e8"
      },
      "source": [
        "### Basic Operations\n",
        "Vectorized operations are fast and expressive.\n",
        "\n",
        "We can compute the arithmetic mean of a numpy array with the `mean` function. We can choose the axis (0 = aggregated by rows, 1 = aggregated by columns)\n",
        "\n",
        "* [Article explaining numpy axes](https://sharpsight.ai/blog/numpy-axes-explained/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excerpt from that article.\n",
        "\n",
        "\n",
        "\n",
        "> In a 2-dimensional NumPy array, the axes are the directions along the rows and columns.\n",
        "> ...axis 0 is the axis that runs downward down the rows.\n",
        "> ...axis 1 is the axis that runs horizontally across the columns.\n",
        ">\n",
        "> To understand how to use the axis parameter in the NumPy functions, it’s very important to understand what the axis parameter actually controls for each function.This is not always as simple as it sounds. For example, in the np.sum() function, the axis parameter behaves in a way that many people think is counter intuitive. In np.sum(), the axis parameter controls which axis will be aggregated. Said differently, the axis parameter controls which axis will be collapsed.\n",
        ">\n",
        "> Remember, functions like sum(), mean(), min(), median(), and other statistical functions aggregate your data.\n",
        ">\n",
        "> When you use the NumPy sum function with the axis parameter, the axis that you specify is the axis that gets collapsed.\n",
        ">\n",
        "> When we set axis = 0, the function actually sums down the columns. The result is a new NumPy array that contains the sum of each column. Why? Doesn’t axis 0 refer to the rows?...As I mentioned earlier, the axis parameter indicates which axis gets collapsed. So when we set axis = 0, we’re not summing across the rows. When we set axis = 0, we’re aggregating the data such that we collapse the rows … we collapse axis 0.\n",
        ">\n",
        "> Recall ... that axis 1 refers to the horizontal direction across the columns. That means that the code np.sum(np_array_2d, axis = 1) collapses the columns during the summation. As I mentioned earlier, this confuses many beginners. They expect that by setting axis = 1, NumPy would sum down the columns, but that’s not how it works. The code has the effect of summing across the columns. It collapses axis 1."
      ],
      "metadata": {
        "id": "7F6xehLIB_OL"
      },
      "id": "7F6xehLIB_OL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Other functions\n",
        "\n",
        "We can compute other statistics in the same way, the most common are:\n",
        "\n",
        "* Standard deviation -- `np.std`\n",
        "* Variance -- `np.var`\n",
        "* Minimum -- `np.min`\n",
        "* Maximum -- `np.max`\n",
        "* Summation -- `np.sum`\n",
        "* Product -- `np.prod`\n",
        "* Cummulative summation -- `np.cumsum`\n",
        "* Unique values -- `np.unique`\n",
        "\n",
        "Let's try all of this functions~\n"
      ],
      "metadata": {
        "id": "cKcq6yzDB-kZ"
      },
      "id": "cKcq6yzDB-kZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019edc90",
      "metadata": {
        "id": "019edc90"
      },
      "outputs": [],
      "source": [
        "x = np.arange(1, 6)   # 1..5\n",
        "print(\"x:\", x)\n",
        "print(\"sum:\", x.sum())\n",
        "print(\"mean:\", x.mean())\n",
        "print(\"std:\", x.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try with a multidimensional array."
      ],
      "metadata": {
        "id": "4bIvnNgw82Ws"
      },
      "id": "4bIvnNgw82Ws"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4JjCWpMz81Kf"
      },
      "id": "4JjCWpMz81Kf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was just a quick look to the basics of NumPy. Here I give you a list of extra resources if you want to understand better NumPy\n",
        "\n",
        "* [Visual guide to NumPy](https://medium.com/better-programming/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d)\n",
        "* [The absolute guide for beginners](https://numpy.org/devdocs/user/absolute_beginners.html)"
      ],
      "metadata": {
        "id": "7ENy3k_H_3WV"
      },
      "id": "7ENy3k_H_3WV"
    },
    {
      "cell_type": "markdown",
      "id": "7db1493f",
      "metadata": {
        "id": "7db1493f"
      },
      "source": [
        "## Exercise 1 (NumPy Warm‑Up)\n",
        "\n",
        "1. Create an array of random numbers of shape (20,)\n",
        "    * Print the shape of the array\n",
        "2. **Reshape** it into **2 rows**\n",
        "3. Compute the **sum, mean and std of each row**\n",
        "    * Before computing, guess what is the shape of the output statistics\n",
        "4. **Reshape** it into **4 rows**\n",
        "5. Compute the **sum, mean and std of each column**.\n",
        "    * Before computing, guess what is the shape of the output statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a92824",
      "metadata": {
        "id": "37a92824"
      },
      "outputs": [],
      "source": [
        "# TODO: Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e2ffc2",
      "metadata": {
        "id": "d5e2ffc2"
      },
      "source": [
        "# Session 2 — pandas Basics\n",
        "\n",
        "Pandas is a newer package built on top of NumPy that provides an efficient implementation of a `DataFrame`.\n",
        "\n",
        "``DataFrame``s are essentially multidimensional arrays with attached row and column labels, often with heterogeneous types and/or missing data.\n",
        "As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\n",
        "\n",
        "As we've seen, NumPy's `ndarray` data structure provides essential features for the type of **clean, well-organized data typically seen in numerical computing tasks.**\n",
        "\n",
        "While it serves this purpose very well, its limitations become clear when we need more flexibility (e.g., attaching labels to data, working with missing data, etc.) and when attempting operations that do not map well to element-wise broadcasting (e.g., groupings, pivots, etc.), each of which is an important piece of analyzing the less structured data available in many forms in the world around us.\n",
        "\n",
        "Pandas, and in particular its `Series` and `DataFrame` objects, builds on the NumPy array structure and provides efficient access to these sorts of \"data munging\" tasks that occupy much of a data scientist's time.\n",
        "\n",
        "pandas is the main tool for **tabular data** (rows & columns). Core objects are:\n",
        "- **Series**: 1D labeled array\n",
        "- **DataFrame**: 2D labeled table of columns, each a Series\n",
        "\n",
        "We'll cover:\n",
        "- Creating Series/DataFrames\n",
        "- Loading CSV files with `pd.read_csv`\n",
        "- Inspecting with `.head()`, `.info()`, `.describe()`\n",
        "- Selecting with `[]`, `.loc`, `.iloc`\n",
        "- Basic stats & filtering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6R_i3WqmOS"
      },
      "source": [
        "## Introducing Pandas Objects"
      ],
      "id": "Ce6R_i3WqmOS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIsz8vZOqmOU"
      },
      "source": [
        "At a very basic level, Pandas objects can be thought of as enhanced versions of NumPy structured arrays in which the rows and columns are identified with labels rather than simple integer indices.\n",
        "As we will see during the course of this session, Pandas provides a host of useful tools, methods, and functionality on top of the basic data structures, but nearly everything that follows will require an understanding of what these structures are.\n",
        "Thus, before we go any further, let's take a look at these three fundamental Pandas data structures: the `Series`, `DataFrame`, and `Index`.\n",
        "\n",
        "We will start our code sessions with the standard Pandas import:"
      ],
      "id": "HIsz8vZOqmOU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "qndi9JXKqmOV"
      },
      "outputs": [],
      "source": [],
      "id": "qndi9JXKqmOV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4kSBgR7qmOV"
      },
      "source": [
        "## The Pandas Series Object\n",
        "\n",
        "A Pandas `Series` is a one-dimensional array of indexed data.\n",
        "It can be created from a list or array as follows:"
      ],
      "id": "i4kSBgR7qmOV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "IWhjN0OZqmOW"
      },
      "outputs": [],
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
        "data"
      ],
      "id": "IWhjN0OZqmOW"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PXDM4SncQ-9v"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PXDM4SncQ-9v"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIw_uo4XRDKH"
      },
      "execution_count": null,
      "outputs": [],
      "id": "aIw_uo4XRDKH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV7ILbiKqmOW"
      },
      "source": [
        "The `Series` combines a sequence of values with an explicit sequence of indices, which we can access with the `values` and `index` attributes.\n",
        "The `values` are simply a familiar NumPy array:"
      ],
      "id": "vV7ILbiKqmOW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8pH_HTQ9qmOW"
      },
      "outputs": [],
      "source": [],
      "id": "8pH_HTQ9qmOW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djRcjpGpqmOX"
      },
      "source": [
        "The `index` is an array-like object of type `pd.Index`, which we'll discuss in more detail momentarily:"
      ],
      "id": "djRcjpGpqmOX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Z7UZ9__QqmOX"
      },
      "outputs": [],
      "source": [],
      "id": "Z7UZ9__QqmOX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElYVmm9EqmOX"
      },
      "source": [
        "Like with a NumPy array, data can be accessed by the associated index via the familiar Python square-bracket notation:"
      ],
      "id": "ElYVmm9EqmOX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "tgEFR31vqmOX"
      },
      "outputs": [],
      "source": [
        "data[1]"
      ],
      "id": "tgEFR31vqmOX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "twE9PVwaqmOY"
      },
      "outputs": [],
      "source": [
        "data[1:3]"
      ],
      "id": "twE9PVwaqmOY"
    },
    {
      "cell_type": "code",
      "source": [
        "f_idx = [2,3,0]\n",
        "data[f_idx]"
      ],
      "metadata": {
        "id": "p8HD_I1_RYdK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "p8HD_I1_RYdK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNxvOSnMqmOY"
      },
      "source": [
        "As we will see, though, the Pandas `Series` is much more general and flexible than the one-dimensional NumPy array that it emulates."
      ],
      "id": "FNxvOSnMqmOY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7WIctCCqmOY"
      },
      "source": [
        "### Series as Generalized NumPy Array"
      ],
      "id": "Q7WIctCCqmOY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyeaznwMqmOY"
      },
      "source": [
        "From what we've seen so far, the `Series` object may appear to be basically interchangeable with a one-dimensional NumPy array.\n",
        "The essential difference is that while the NumPy array has an *implicitly defined* integer index used to access the values, the Pandas `Series` has an *explicitly defined* index associated with the values.\n",
        "\n",
        "This explicit index definition gives the `Series` object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type.\n",
        "So, if we wish, we can use strings as an index:"
      ],
      "id": "xyeaznwMqmOY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HFlg4wX-qmOY"
      },
      "outputs": [],
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
        "                 index=['a', 'b', 'c', 'd'])\n",
        "data"
      ],
      "id": "HFlg4wX-qmOY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3_ZlX0FqmOY"
      },
      "source": [
        "And the item access works as expected:"
      ],
      "id": "a3_ZlX0FqmOY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "abLh7QfSqmOY"
      },
      "outputs": [],
      "source": [],
      "id": "abLh7QfSqmOY"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLkFO1J3SEP_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "BLkFO1J3SEP_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpFm1CNdqmOY"
      },
      "source": [
        "We can even use noncontiguous or nonsequential indices:"
      ],
      "id": "WpFm1CNdqmOY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "If5yIzGXqmOY"
      },
      "outputs": [],
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
        "                 index=[2, 5, 3, 7])\n",
        "data"
      ],
      "id": "If5yIzGXqmOY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Gj4nHi3qqmOY"
      },
      "outputs": [],
      "source": [
        "data[5]"
      ],
      "id": "Gj4nHi3qqmOY"
    },
    {
      "cell_type": "code",
      "source": [
        "data.index"
      ],
      "metadata": {
        "id": "5P5RVBLuSKr5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5P5RVBLuSKr5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aghy7eUcqmOY"
      },
      "source": [
        "### Series as Specialized Dictionary\n",
        "\n",
        "In this way, you can think of a Pandas `Series` a bit like a specialization of a Python dictionary.\n",
        "A dictionary is a structure that maps arbitrary keys to a set of arbitrary values, and a `Series` is a structure that maps typed keys to a set of typed values.\n",
        "This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a Pandas `Series` makes it more efficient than Python dictionaries for certain operations.\n",
        "\n",
        "The `Series`-as-dictionary analogy can be made even more clear by constructing a `Series` object directly from a Python dictionary, here the five most populous US states according to the 2020 census:"
      ],
      "id": "aghy7eUcqmOY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "7DeaeqD8qmOZ"
      },
      "outputs": [],
      "source": [
        "population_dict = {'California': 39538223, 'Texas': 29145505,\n",
        "                   'Florida': 21538187, 'New York': 20201249,\n",
        "                   'Pennsylvania': 13002700}\n",
        "population = pd.Series(population_dict)\n",
        "population"
      ],
      "id": "7DeaeqD8qmOZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur2yDC0KqmOZ"
      },
      "source": [
        "From here, typical dictionary-style item access can be performed:"
      ],
      "id": "Ur2yDC0KqmOZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ckuqJn_vqmOZ"
      },
      "outputs": [],
      "source": [
        "population['California']"
      ],
      "id": "ckuqJn_vqmOZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28IPv3_HqmOZ"
      },
      "source": [
        "Unlike a dictionary, though, the `Series` also supports array-style operations such as slicing:"
      ],
      "id": "28IPv3_HqmOZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "JlqZDvk-qmOZ"
      },
      "outputs": [],
      "source": [
        "population['California':'Florida']"
      ],
      "id": "JlqZDvk-qmOZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFIhNS6TqmOZ"
      },
      "source": [
        "## The Pandas DataFrame Object\n",
        "\n",
        "The next fundamental structure in Pandas is the `DataFrame`.\n",
        "Like the `Series` object discussed in the previous section, the `DataFrame` can be thought of either as a generalization of a NumPy array, or as a specialization of a Python dictionary.\n",
        "We'll now take a look at each of these perspectives."
      ],
      "id": "rFIhNS6TqmOZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8BtV3DyqmOZ"
      },
      "source": [
        "### DataFrame as Generalized NumPy Array\n",
        "If a `Series` is an analog of a one-dimensional array with explicit indices, a `DataFrame` is an analog of a two-dimensional array with explicit row and column indices.\n",
        "Just as you might think of a two-dimensional array as an ordered sequence of aligned one-dimensional columns, you can think of a `DataFrame` as a sequence of aligned `Series` objects.\n",
        "Here, by \"aligned\" we mean that they share the same index.\n",
        "\n",
        "To demonstrate this, let's first construct a new `Series` listing the area of each of the five states discussed in the previous section (in square kilometers):"
      ],
      "id": "v8BtV3DyqmOZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "X4PwZPgxqmOa"
      },
      "outputs": [],
      "source": [
        "area_dict = {'California': 423967, 'Texas': 695662, 'Florida': 170312,\n",
        "             'New York': 141297, 'Pennsylvania': 119280}  #dont remove\n",
        "area = pd.Series(area_dict)\n",
        "area"
      ],
      "id": "X4PwZPgxqmOa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o4eXlz8qmOa"
      },
      "source": [
        "Now that we have this along with the `population` Series from before, we can use a dictionary to construct a single two-dimensional object containing this information:"
      ],
      "id": "3o4eXlz8qmOa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8eLS8Q3MqmOa"
      },
      "outputs": [],
      "source": [
        "states = pd.DataFrame({'population': population,\n",
        "                       'area': area})\n",
        "states"
      ],
      "id": "8eLS8Q3MqmOa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEMyY2H2qmOa"
      },
      "source": [
        "Like the `Series` object, the `DataFrame` has an `index` attribute that gives access to the index labels:"
      ],
      "id": "gEMyY2H2qmOa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "WjBEPeXJqmOa"
      },
      "outputs": [],
      "source": [],
      "id": "WjBEPeXJqmOa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvpRHQFBqmOa"
      },
      "source": [
        "Additionally, the `DataFrame` has a `columns` attribute, which is an `Index` object holding the column labels:"
      ],
      "id": "NvpRHQFBqmOa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "hcM6VgzfqmOb"
      },
      "outputs": [],
      "source": [],
      "id": "hcM6VgzfqmOb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf5hlRLRqmOb"
      },
      "source": [
        "Thus the `DataFrame` can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data."
      ],
      "id": "Nf5hlRLRqmOb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE4XP7FNqmOb"
      },
      "source": [
        "### Constructing DataFrame Objects\n",
        "\n",
        "A Pandas `DataFrame` can be constructed in a variety of ways.\n",
        "Here we'll explore several examples."
      ],
      "id": "iE4XP7FNqmOb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK4rubdVqmOb"
      },
      "source": [
        "#### From a single Series object\n",
        "\n",
        "A `DataFrame` is a collection of `Series` objects, and a single-column `DataFrame` can be constructed from a single `Series`:"
      ],
      "id": "IK4rubdVqmOb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ZMw_4PcbqmOb"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(population, columns=['population'])"
      ],
      "id": "ZMw_4PcbqmOb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02XkfSHuqmOb"
      },
      "source": [
        "#### From a dictionary of Series objects\n",
        "\n",
        "As we saw before, a `DataFrame` can be constructed from a dictionary of `Series` objects as well:"
      ],
      "id": "02XkfSHuqmOb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "nEdofmJxqmOc"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'population': population,\n",
        "              'area': area})\n",
        "df"
      ],
      "id": "nEdofmJxqmOc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjAvPDoDqmOc"
      },
      "source": [
        "## The Pandas Index Object\n",
        "\n",
        "As you've seen, the `Series` and `DataFrame` objects both contain an explicit *index* that lets you reference and modify data.\n",
        "This `Index` object is an interesting structure in itself, and it can be thought of either as an *immutable array* or as an *ordered set* (technically a multiset, as `Index` objects may contain repeated values).\n",
        "Those views have some interesting consequences in terms of the operations available on `Index` objects.\n",
        "As a simple example, let's construct an `Index` from a list of integers:"
      ],
      "id": "HjAvPDoDqmOc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6Eiiwfi3qmOc"
      },
      "outputs": [],
      "source": [
        "ind = pd.Index([2, 3, 5, 7, 11])\n",
        "ind"
      ],
      "id": "6Eiiwfi3qmOc"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWtFrV_cIFV5"
      },
      "id": "CWtFrV_cIFV5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Indexing and Selection"
      ],
      "metadata": {
        "id": "NE7yn5agbzSV"
      },
      "id": "NE7yn5agbzSV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rza559ULn5sE"
      },
      "source": [
        "### Data Selection in Series\n",
        "\n",
        "As learned before, a `Series` object acts in many ways like a one-dimensional NumPy array, and in many ways like a standard Python dictionary.\n",
        "If you keep these two overlapping analogies in mind, it will help you understand the patterns of data indexing and selection in these arrays."
      ],
      "id": "rza559ULn5sE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DwZrOvGn5sE"
      },
      "source": [
        "### Series as Dictionary\n",
        "\n",
        "Like a dictionary, the `Series` object provides a mapping from a collection of keys to a collection of values:"
      ],
      "id": "0DwZrOvGn5sE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0ALLSGjNn5sF"
      },
      "outputs": [],
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
        "                 index=['a', 'b', 'c', 'd'])\n",
        "data"
      ],
      "id": "0ALLSGjNn5sF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "SWtbdwpJn5sG"
      },
      "outputs": [],
      "source": [
        "data['b']"
      ],
      "id": "SWtbdwpJn5sG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_mYOLpOn5sG"
      },
      "source": [
        "We can also use dictionary-like Python expressions and methods to examine the keys/indices and values:"
      ],
      "id": "G_mYOLpOn5sG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "iefPoXTHn5sG"
      },
      "outputs": [],
      "source": [
        "'a' in data"
      ],
      "id": "iefPoXTHn5sG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-Ob8XMD1n5sH"
      },
      "outputs": [],
      "source": [
        "data.keys()"
      ],
      "id": "-Ob8XMD1n5sH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dveKQ3mCn5sH"
      },
      "outputs": [],
      "source": [
        "list(data.items())"
      ],
      "id": "dveKQ3mCn5sH"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rtaN_EY-JmQ8"
      },
      "id": "rtaN_EY-JmQ8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvq6tNVmn5sI"
      },
      "source": [
        "### Indexers: loc and iloc\n",
        "\n",
        "If your `Series` has an explicit integer index, an indexing operation such as `data[1]` will use the explicit indices, while a slicing operation like `data[1:3]` will use the implicit Python-style indices:"
      ],
      "id": "Zvq6tNVmn5sI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "EHVvPtKtn5sJ"
      },
      "outputs": [],
      "source": [
        "data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
        "data"
      ],
      "id": "EHVvPtKtn5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "PS6x9hcbn5sJ"
      },
      "outputs": [],
      "source": [
        "# explicit index when indexing\n",
        "data[1]"
      ],
      "id": "PS6x9hcbn5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "WDrQv_Iyn5sJ"
      },
      "outputs": [],
      "source": [
        "# implicit index when slicing\n",
        "data[1:3]"
      ],
      "id": "WDrQv_Iyn5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulIMXlFyn5sJ"
      },
      "source": [
        "Because of this potential confusion in the case of integer indexes, Pandas provides some special *indexer* attributes that explicitly expose certain indexing schemes.\n",
        "These are not functional methods, but attributes that expose a particular slicing interface to the data in the `Series`.\n",
        "\n",
        "First, the `loc` attribute allows indexing and slicing that always references the explicit index:"
      ],
      "id": "ulIMXlFyn5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ETxLlnV7n5sJ"
      },
      "outputs": [],
      "source": [
        "data.loc[1]"
      ],
      "id": "ETxLlnV7n5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Lnh2VjByn5sJ"
      },
      "outputs": [],
      "source": [
        "data.loc[1:3]"
      ],
      "id": "Lnh2VjByn5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIyoIYfDn5sJ"
      },
      "source": [
        "The `iloc` attribute allows indexing and slicing that always references the implicit Python-style index:"
      ],
      "id": "VIyoIYfDn5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-W_jDQofn5sJ"
      },
      "outputs": [],
      "source": [
        "data.iloc[1]"
      ],
      "id": "-W_jDQofn5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "yVmHdkpNn5sJ"
      },
      "outputs": [],
      "source": [
        "data.iloc[1:3]"
      ],
      "id": "yVmHdkpNn5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUyJMakon5sJ"
      },
      "source": [
        "One guiding principle of Python code is that \"explicit is better than implicit.\"\n",
        "The explicit nature of `loc` and `iloc` makes them helpful in maintaining clean and readable code; especially in the case of integer indexes, using them consistently can prevent subtle bugs due to the mixed indexing/slicing convention."
      ],
      "id": "YUyJMakon5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs7-NERgn5sJ"
      },
      "source": [
        "## Data Selection in DataFrames\n",
        "\n",
        "Recall that a `DataFrame` acts in many ways like a two-dimensional or structured array, and in other ways like a dictionary of `Series` structures sharing the same index.\n",
        "These analogies can be helpful to keep in mind as we explore data selection within this structure."
      ],
      "id": "rs7-NERgn5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBYxsDSTn5sJ"
      },
      "source": [
        "### DataFrame as Dictionary\n",
        "\n",
        "The first analogy we will consider is the `DataFrame` as a dictionary of related `Series` objects.\n",
        "Let's return to our example of areas and populations of states:"
      ],
      "id": "mBYxsDSTn5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "oFTXIetFn5sJ"
      },
      "outputs": [],
      "source": [
        "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
        "                  'Florida': 170312, 'New York': 141297,\n",
        "                  'Pennsylvania': 119280})\n",
        "pop = pd.Series({'California': 39538223, 'Texas': 29145505,\n",
        "                 'Florida': 21538187, 'New York': 20201249,\n",
        "                 'Pennsylvania': 13002700})\n",
        "data = pd.DataFrame({'area':area, 'pop':pop}) # dont remove\n",
        "data"
      ],
      "id": "oFTXIetFn5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mQcPKfqn5sJ"
      },
      "source": [
        "The individual `Series` that make up the columns of the `DataFrame` can be accessed via dictionary-style indexing of the column name:"
      ],
      "id": "9mQcPKfqn5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ok1FeIOin5sJ"
      },
      "outputs": [],
      "source": [
        "data['area']"
      ],
      "id": "ok1FeIOin5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwUqJ5w5n5sJ"
      },
      "source": [
        "Equivalently, we can use attribute-style access with column names that are strings:"
      ],
      "id": "jwUqJ5w5n5sJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "IKy3QBx7n5sJ"
      },
      "outputs": [],
      "source": [
        "data.area"
      ],
      "id": "IKy3QBx7n5sJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvrAgeu-n5sK"
      },
      "source": [
        "Though this is a useful shorthand, keep in mind that it does not work for all cases!\n",
        "For example, if the column names are not strings, or if the column names conflict with methods of the `DataFrame`, this attribute-style access is not possible.\n",
        "For example, the `DataFrame` has a `pop` method, so `data.pop` will point to this rather than the `pop` column:"
      ],
      "id": "wvrAgeu-n5sK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZsxLWKRn5sN"
      },
      "source": [
        "In particular, you should avoid the temptation to try column assignment via attributes (i.e., use `data['pop'] = z` rather than `data.pop = z`).\n",
        "\n",
        "Like with the `Series` objects discussed earlier, this dictionary-style syntax can also be used to modify the object, in this case adding a new column:"
      ],
      "id": "cZsxLWKRn5sN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "0dqcGexjn5sN"
      },
      "outputs": [],
      "source": [
        "data['density'] = data['pop'] / data['area']\n",
        "data"
      ],
      "id": "0dqcGexjn5sN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLYHDgrIn5sN"
      },
      "source": [
        "This shows a preview of the straightforward syntax of element-by-element arithmetic between `Series` objects; we'll dig into this further in a bit"
      ],
      "id": "MLYHDgrIn5sN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOmPAKRrn5sN"
      },
      "source": [
        "### DataFrame as Two-Dimensional Array\n",
        "\n",
        "We can also view the `DataFrame` as an enhanced two-dimensional array.\n",
        "We can examine the raw underlying data array using the `values` attribute:"
      ],
      "id": "OOmPAKRrn5sN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dxw9e5PTn5sN"
      },
      "outputs": [],
      "source": [
        "data.values"
      ],
      "id": "dxw9e5PTn5sN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgwtuh0On5sN"
      },
      "source": [
        "With this picture in mind, many familiar array-like operations can be done on the `DataFrame` itself.\n",
        "For example, we can transpose the full `DataFrame` to swap rows and columns:"
      ],
      "id": "Cgwtuh0On5sN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "OQ8l6GIPn5sO"
      },
      "outputs": [],
      "source": [
        "data.T"
      ],
      "id": "OQ8l6GIPn5sO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzHq7Jcdn5sO"
      },
      "source": [
        "For array-style indexing Pandas again uses the `loc` and `iloc` indexers mentioned earlier.\n",
        "Using the `iloc` indexer, we can index the underlying array as if it were a simple NumPy array (using the implicit Python-style index), but the `DataFrame` index and column labels are maintained in the result:"
      ],
      "id": "ZzHq7Jcdn5sO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HedpAwQjn5sO"
      },
      "outputs": [],
      "source": [
        "data.iloc[:3, :2]"
      ],
      "id": "HedpAwQjn5sO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT_NRT0hn5sO"
      },
      "source": [
        "Similarly, using the `loc` indexer we can index the underlying data in an array-like style but using the explicit index and column names:"
      ],
      "id": "iT_NRT0hn5sO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "LzoEQhOpn5sO"
      },
      "outputs": [],
      "source": [
        "data.loc[:'Florida', :'pop']"
      ],
      "id": "LzoEQhOpn5sO"
    },
    {
      "cell_type": "code",
      "source": [
        "data['area']['California']"
      ],
      "metadata": {
        "id": "nJv9QfJHg5Qy"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nJv9QfJHg5Qy"
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc['California','area']"
      ],
      "metadata": {
        "id": "li0VPGDQhB6a"
      },
      "execution_count": null,
      "outputs": [],
      "id": "li0VPGDQhB6a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqDo2JmCn5sO"
      },
      "source": [
        "Any of the familiar NumPy-style data access patterns can be used within these indexers.\n",
        "For example, in the `loc` indexer we can combine masking and fancy indexing as follows:"
      ],
      "id": "cqDo2JmCn5sO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4Tt4MErcn5sO"
      },
      "outputs": [],
      "source": [
        "data.loc[data.density > 120, ['pop', 'density']]"
      ],
      "id": "4Tt4MErcn5sO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQFd-Hnan5sO"
      },
      "source": [
        "Any of these indexing conventions may also be used to set or modify values; this is done in the standard way that you might be accustomed to from working with NumPy:"
      ],
      "id": "VQFd-Hnan5sO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "neHFKdtun5sO"
      },
      "outputs": [],
      "source": [
        "data.iloc[0, 2] = 90\n",
        "data"
      ],
      "id": "neHFKdtun5sO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn56ASg9n5sO"
      },
      "source": [
        "To build up your fluency in Pandas data manipulation, I suggest spending some time with a simple `DataFrame` and exploring the types of indexing, slicing, masking, and fancy indexing that are allowed by these various indexing approaches."
      ],
      "id": "Pn56ASg9n5sO"
    },
    {
      "cell_type": "markdown",
      "id": "e9df4f2b",
      "metadata": {
        "id": "e9df4f2b"
      },
      "source": [
        "### Loading Data\n",
        "The most common path is CSV. Keep the file in the same folder or provide a full path.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d24ab8d7",
      "metadata": {
        "id": "d24ab8d7"
      },
      "outputs": [],
      "source": [
        "df_example = pd.read_csv('sample_data/california_housing_train.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f39d3546",
      "metadata": {
        "id": "f39d3546"
      },
      "source": [
        "### Inspecting Data\n",
        "Use `.head()`, `.info()`, `.describe()` to quickly understand structure and types.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v3OZritjLZVY"
      },
      "id": "v3OZritjLZVY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pV9a7-lULe-r"
      },
      "id": "pV9a7-lULe-r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MCiZkAtiLfGJ"
      },
      "id": "MCiZkAtiLfGJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f591f1e8",
      "metadata": {
        "id": "f591f1e8"
      },
      "source": [
        "### Practice Selecting Columns & Rows\n",
        "- Column by label: `df['col']`\n",
        "- Rows by label/conditions (explicit index): `df.loc[...]`\n",
        "- Rows by position (implicit index): `df.iloc[...]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8507bfd2",
      "metadata": {
        "id": "8507bfd2"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca57b999",
      "metadata": {
        "id": "ca57b999"
      },
      "source": [
        "### Basic Operations\n",
        "Common quick summaries:\n",
        "- `df['col'].mean()`\n",
        "- `df['col'].value_counts()`\n",
        "- `df.describe()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39e1c1d0",
      "metadata": {
        "id": "39e1c1d0"
      },
      "outputs": [],
      "source": [
        "mean_total_rooms = df_example[\"total_rooms\"].mean()\n",
        "mean_total_rooms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts_total_rooms = df_example[\"total_rooms\"].value_counts()\n",
        "counts_total_rooms"
      ],
      "metadata": {
        "id": "TtzpNAnYMg0m"
      },
      "id": "TtzpNAnYMg0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3d448251",
      "metadata": {
        "id": "3d448251"
      },
      "source": [
        "## ✅ Exercise 2 (pandas Basics)\n",
        "Using the california housing dataset that we loaded before:\n",
        "\n",
        "- Compute the **maximum median income**.\n",
        "- Compute the **minimum median house value**\n",
        "- Show all rows where **total_beddroms >= 5**.\n",
        "- Display **value counts** of the **total bedrooms** column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b89a1b0",
      "metadata": {
        "id": "8b89a1b0"
      },
      "outputs": [],
      "source": [
        "# TODO: Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84901117",
      "metadata": {
        "id": "84901117"
      },
      "source": [
        "## Session 3 — pandas for Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHptltNi1dkw"
      },
      "source": [
        "### Combining Datasets: concat and append"
      ],
      "id": "RHptltNi1dkw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj8kAN1t1dk0"
      },
      "source": [
        "Some of the most interesting studies of data come from combining different data sources.\n",
        "These operations can involve anything from very straightforward concatenation of two different datasets to more complicated database-style joins and merges that correctly handle any overlaps between the datasets.\n",
        "`Series` and ``DataFrame``s are built with this type of operation in mind, and Pandas includes functions and methods that make this sort of data wrangling fast and straightforward.\n",
        "\n",
        "Here we'll take a look at simple concatenation of `Series` and ``DataFrame``s with the `pd.concat` function in Pandas.\n",
        "\n",
        "We begin with the standard imports:"
      ],
      "id": "aj8kAN1t1dk0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll combine data.\n",
        "\n",
        "**Combining**\n",
        "- `pd.concat([df1, df2], axis=0)` to stack rows.\n",
        "- `pd.concat([df1, df2], axis=1)` to concatenate columns.\n"
      ],
      "metadata": {
        "id": "Nt-0Yz-ANePh"
      },
      "id": "Nt-0Yz-ANePh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "721NjtCB1dk2"
      },
      "source": [
        "For convenience, we'll define this function, which creates a `DataFrame` of a particular form that will be useful in the following examples:"
      ],
      "id": "721NjtCB1dk2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "qvc7RF-J1dk2"
      },
      "outputs": [],
      "source": [
        "def make_df(cols, ind):\n",
        "    \"\"\"Quickly make a DataFrame\"\"\"\n",
        "    data = {c: [str(c) + str(i) for i in ind]\n",
        "            for c in cols}\n",
        "    return pd.DataFrame(data, ind)\n",
        "\n",
        "# example DataFrame\n",
        "make_df('ABC', range(3))"
      ],
      "id": "qvc7RF-J1dk2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWtyc8CA1dk3"
      },
      "source": [
        "In addition, we'll create a quick class that allows us to display multiple ``DataFrame``s side by side. The code makes use of the special `_repr_html_` method, which IPython/Jupyter uses to implement its rich object display:"
      ],
      "id": "LWtyc8CA1dk3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "oitDY1ak1dk3"
      },
      "outputs": [],
      "source": [
        "class display(object):\n",
        "    \"\"\"Display HTML representation of multiple objects\"\"\"\n",
        "    template = \"\"\"<div style=\"float: left; padding: 10px;\">\n",
        "    <p style='font-family:\"Courier New\", Courier, monospace'>{0}</p>{1}\n",
        "    </div>\"\"\"\n",
        "    def __init__(self, *args):\n",
        "        self.args = args\n",
        "\n",
        "    def _repr_html_(self):\n",
        "        return '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n",
        "                         for a in self.args)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '\\n\\n'.join(a + '\\n' + repr(eval(a))\n",
        "                           for a in self.args)\n"
      ],
      "id": "oitDY1ak1dk3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj3W88Tb1dk4"
      },
      "source": [
        "The use of this will become clearer as we continue our discussion in the following section."
      ],
      "id": "bj3W88Tb1dk4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJcUPVoF1dk5"
      },
      "source": [
        "## Simple Concatenation with pd.concat"
      ],
      "id": "rJcUPVoF1dk5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Tf6bKA1dk5"
      },
      "source": [
        "The `pd.concat` function provides a similar syntax to `np.concatenate` but contains a number of options that we'll discuss momentarily:\n",
        "\n",
        "```python\n",
        "# Signature in Pandas v1.3.5\n",
        "pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None,\n",
        "          levels=None, names=None, verify_integrity=False,\n",
        "          sort=False, copy=True)\n",
        "```\n",
        "\n",
        "`pd.concat` can be used for a simple concatenation of `Series` or `DataFrame` objects, just as `np.concatenate` can be used for simple concatenations of arrays:"
      ],
      "id": "x1Tf6bKA1dk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wjN1M1av1dk5"
      },
      "outputs": [],
      "source": [
        "ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
        "ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
        "#concatenate ser1 and ser2\n"
      ],
      "id": "wjN1M1av1dk5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxlk5UcX1dk5"
      },
      "source": [
        "It also works to concatenate higher-dimensional objects, such as ``DataFrame``s:"
      ],
      "id": "pxlk5UcX1dk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Stvf37b21dk5"
      },
      "outputs": [],
      "source": [
        "df1 = make_df('AB', [1, 2])\n",
        "df2 = make_df('AB', [3, 4])\n",
        "concat_df = pd.concat([df1, df2])\n",
        "display('df1', 'df2', 'concat_df' )"
      ],
      "id": "Stvf37b21dk5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmJnxU1q1dk5"
      },
      "source": [
        "It's default behavior is to concatenate row-wise within the `DataFrame` (i.e., `axis=0`).\n",
        "Like `np.concatenate`, `pd.concat` allows specification of an axis along which concatenation will take place.\n",
        "Consider the following example:"
      ],
      "id": "KmJnxU1q1dk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "DIFi7tjY1dk6"
      },
      "outputs": [],
      "source": [
        "df3 = make_df('AB', [0, 1])\n",
        "df4 = make_df('CD', [0, 1])\n",
        "concat_df = pd.concat([df3, df4], axis=\"columns\")\n",
        "display('df3', 'df4',\"concat_df\" )"
      ],
      "id": "DIFi7tjY1dk6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k4hjhhA1dk6"
      },
      "source": [
        "We could have equivalently specified ``axis=1``; here we've used the more intuitive ``axis='columns'``."
      ],
      "id": "7k4hjhhA1dk6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tkrcfj91dk6"
      },
      "source": [
        "### Duplicate Indices\n",
        "\n",
        "`pd.concat` that is,  Pandas concatenation, *preserves indices*, even if the result will have duplicate indices!\n",
        "Consider this short example:"
      ],
      "id": "6tkrcfj91dk6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "f6z0CB0I1dk6"
      },
      "outputs": [],
      "source": [
        "x = make_df('AB', [0, 1])\n",
        "y = make_df('AB', [2, 3])\n",
        "y.index = x.index  # make indices match\n",
        "concat_df = pd.concat([x, y])\n",
        "display('x', 'y', \"concat_df\" )"
      ],
      "id": "f6z0CB0I1dk6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im7HRL-L1dk6"
      },
      "source": [
        "Notice the repeated indices in the result.\n",
        "While this is valid within ``DataFrame``s, the outcome is often undesirable.\n",
        "`pd.concat` gives us a few ways to handle it."
      ],
      "id": "Im7HRL-L1dk6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJcGORrD1dk6"
      },
      "source": [
        "#### Treating repeated indices as an error\n",
        "\n",
        "If you'd like to simply verify that the indices in the result of `pd.concat` do not overlap, you can include the `verify_integrity` flag.\n",
        "With this set to `True`, the concatenation will raise an exception if there are duplicate indices.\n",
        "Here is an example, where for clarity we'll catch and print the error message:"
      ],
      "id": "dJcGORrD1dk6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Pzr7ESZH1dk6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    #concatenate x and y DataFrames while verifying integrity\n",
        "    pd.concat([x, y], verify_integrity=True)\n",
        "except ValueError as e:\n",
        "    print(\"ValueError:\", e)"
      ],
      "id": "Pzr7ESZH1dk6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe7dU0EL1dk7"
      },
      "source": [
        "#### Ignoring the index\n",
        "\n",
        "Sometimes the index itself does not matter, and you would prefer it to simply be ignored.\n",
        "This option can be specified using the `ignore_index` flag.\n",
        "With this set to `True`, the concatenation will create a new integer index for the resulting `DataFrame`:"
      ],
      "id": "pe7dU0EL1dk7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9M00r2zl1dk7"
      },
      "outputs": [],
      "source": [
        "#concatenate x and y DataFrames while ignoring the index\n",
        "concat_df =pd.concat([x, y], ignore_index=True)\n",
        "display('x', 'y', \"concat_df\" )"
      ],
      "id": "9M00r2zl1dk7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTXiQcCO1dk7"
      },
      "source": [
        "### Concatenation with Joins\n",
        "\n",
        "In the short examples we just looked at, we were mainly concatenating ``DataFrame``s with shared column names.\n",
        "In practice, data from different sources might have different sets of column names, and `pd.concat` offers several options in this case.\n",
        "Consider the concatenation of the following two ``DataFrame``s, which have some (but not all!) columns in common:"
      ],
      "id": "kTXiQcCO1dk7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "d9L5bxC41dk7"
      },
      "outputs": [],
      "source": [
        "df5 = make_df('ABC', [1, 2])\n",
        "df6 = make_df('BCD', [3, 4])\n",
        "concat_df = pd.concat([df5, df6])\n",
        "display('df5', 'df6', \"concat_df\" )"
      ],
      "id": "d9L5bxC41dk7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFFH5zZr1dk8"
      },
      "source": [
        "The default behavior is to fill entries for which no data is available with NA values.\n",
        "To change this, we can adjust the `join` parameter of the `concat` function.\n",
        "By default, the join is a union of the input columns (`join='outer'`), but we can change this to an intersection of the columns using `join='inner'`:"
      ],
      "id": "NFFH5zZr1dk8"
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat?"
      ],
      "metadata": {
        "id": "loP9-drg2o8C"
      },
      "execution_count": null,
      "outputs": [],
      "id": "loP9-drg2o8C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "eHrV36T01dk8"
      },
      "outputs": [],
      "source": [
        "concat_df = pd.concat([df5, df6], join='inner')\n",
        "display('df5', 'df6',\"concat_df\" )"
      ],
      "id": "eHrV36T01dk8"
    },
    {
      "cell_type": "markdown",
      "id": "859fce91",
      "metadata": {
        "id": "859fce91"
      },
      "source": [
        "## Wrap‑Up & Notes\n",
        "- **NumPy** is the foundation (fast arrays); we used only what’s needed to read/understand pandas.\n",
        "- **pandas** is the main tool for data analysis: load, inspect, select, aggregate, combine, and visualize.\n",
        "\n",
        "\n",
        "And that's it for today's lab session. Next week we will study more advance data manipulation functions such as aggregation and data visualization using pandas.\n",
        "\n",
        "See you next week!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "baf4ZtCKO92H"
      },
      "id": "baf4ZtCKO92H",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}